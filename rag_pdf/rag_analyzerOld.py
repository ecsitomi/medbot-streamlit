# =============================================================================
# rag_pdf/rag_analyzerOLD.py
# =============================================================================
"""
RAG alap√∫ elemz√©s √©s v√°laszgener√°l√°s
"""
import streamlit as st
from typing import Dict, Any, List, Optional
from datetime import datetime
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import Document
from langchain.chains import LLMChain
import json
from pathlib import Path
import os

from .pdf_processor import PDFProcessor
from .vector_store import VectorStoreManager
from .config import RAG_CONFIG

def translate_text(text: str, openai_api_key: str) -> str:
    """Egy√©ni sz√∂veg leford√≠t√°sa angolra"""
    if not text:
        return ""
    llm = ChatOpenAI(openai_api_key=openai_api_key, temperature=0)
    return llm.predict(f"Translate the following Hungarian medical term or sentence to English: '{text}'").strip()

def translate_list(texts: List[str], openai_api_key: str) -> List[str]:
    """Lista ford√≠t√°sa angolra"""
    return [translate_text(t, openai_api_key) for t in texts if t]

def translate_patient_data(patient_data: Dict[str, Any], openai_api_key: str) -> Dict[str, Any]:
    """Betegadatok leford√≠t√°sa angolra a RAG keres√©shez"""
    translated = patient_data.copy()
    
    translated['symptoms'] = translate_list(patient_data.get('symptoms', []), openai_api_key)
    translated['diagnosis'] = translate_text(patient_data.get('diagnosis', ''), openai_api_key)
    translated['existing_conditions'] = translate_list(patient_data.get('existing_conditions', []), openai_api_key)
    translated['medications'] = translate_list(patient_data.get('medications', []), openai_api_key)
    
    return translated

class RAGAnalyzer:
    """RAG alap√∫ Medline PDF elemz≈ë"""
    
    def __init__(self, openai_api_key: str):
        self.pdf_processor = PDFProcessor()
        self.vector_store_manager = VectorStoreManager(openai_api_key)
        
        # LLM inicializ√°l√°sa
        self.llm = ChatOpenAI(
            openai_api_key=openai_api_key,
            model_name=RAG_CONFIG["llm"]["model"],
            temperature=RAG_CONFIG["llm"]["temperature"],
            max_tokens=RAG_CONFIG["llm"]["max_tokens"]
        )
        
        # Prompt template
        '''
        self.prompt_template = ChatPromptTemplate.from_messages([
            ("system", """Te egy eg√©szs√©g√ºgyi szak√©rt≈ë vagy, aki a Medline Plus inform√°ci√≥k alapj√°n 
            szem√©lyre szabott tan√°csokat ad. A k√∂vetkez≈ë relev√°ns inform√°ci√≥k √°llnak rendelkez√©sedre 
            a beteg √°llapot√°val kapcsolatban.
            
            Kontextus a Medline dokumentumokb√≥l:
            {context}
            
            A beteg adatai:
            - √âletkor: {age} √©v
            - Nem: {gender}
            - T√ºnetek: {symptoms}
            - Id≈ëtartam: {duration}
            - S√∫lyoss√°g: {severity}
            - Diagn√≥zis: {diagnosis}
            - Megl√©v≈ë betegs√©gek: {existing_conditions}
            - Gy√≥gyszerek: {medications}
            """),
            ("human", """A fenti inform√°ci√≥k alapj√°n k√©rlek adj r√©szletes v√°laszt a k√∂vetkez≈ë k√©rd√©sekre:

            1. **Milyen beteg a p√°ciens?** - Mi lehet a probl√©ma a Medline inform√°ci√≥k alapj√°n?
            2. **Mit tehet a t√ºnetek ellen?** - Milyen otthoni kezel√©sek, √©letm√≥dbeli v√°ltoztat√°sok seg√≠thetnek?
            3. **Milyen orvoshoz forduljon?** - Melyik szakorvost aj√°nlod √©s mi√©rt?
            4. **Tov√°bbi hasznos inform√°ci√≥k** - Ami fontos lehet a beteg sz√°m√°ra

            K√©rlek struktur√°lt, k√∂nnyen √©rthet≈ë v√°laszt adj magyarul!""")
        ])
        '''
        self.prompt_template = ChatPromptTemplate.from_messages([
            ("system", """You are a healthcare expert providing personalized advice based on Medline Plus information. 
            The following relevant information is available about the patient's condition.

            Context from Medline documents:
            {context}

            Patient data:
            - Age: {age} years
            - Gender: {gender}
            - Symptoms: {symptoms}
            - Duration: {duration}
            - Severity: {severity}
            - Diagnosis: {diagnosis}
            - Pre-existing conditions: {existing_conditions}
            - Medications: {medications}
            """),
                ("human", """Based on the above information, please provide a detailed answer to the following questions:

            1. **What might be the patient's condition?** ‚Äì What could be the issue based on the Medline information?
            2. **What can the patient do about the symptoms?** ‚Äì What home treatments or lifestyle changes could help?
            3. **Which doctor should the patient consult?** ‚Äì What kind of specialist do you recommend and why?
            4. **Additional useful information** ‚Äì Anything else that could be important for the patient

            Please give a clear, structured, and easy-to-understand answer in **Hungarian**!""")
        ])

        
        # LLM Chain
        self.chain = LLMChain(llm=self.llm, prompt=self.prompt_template)
    
    def prepare_context(self, relevant_docs: List[Document]) -> str:
        """Relev√°ns dokumentumok kontextuss√° alak√≠t√°sa"""
        if not relevant_docs:
            return "Nincs relev√°ns Medline inform√°ci√≥."
        
        context_parts = []
        for i, doc in enumerate(relevant_docs, 1):
            source = doc.metadata.get('source', 'Unknown')
            content = doc.page_content[:500]  # Max 500 karakter dokumentumonk√©nt
            context_parts.append(f"[{i}. Forr√°s: {source}]\n{content}...")
        
        return "\n\n".join(context_parts)
    
    def analyze_patient_with_rag(self, patient_data: Dict[str, Any]) -> Dict[str, Any]:
        """Beteg elemz√©se RAG haszn√°lat√°val"""
        st.info("üîç RAG alap√∫ elemz√©s ind√≠t√°sa...")

        try:
            # PDF-ek feldolgoz√°sa
            if not hasattr(self.vector_store_manager, 'vectorstore') or self.vector_store_manager.vectorstore is None:
                st.info("üìÑ PDF-ek feldolgoz√°sa √©s indexel√©se...")
                chunks = self.pdf_processor.process_pdfs()
                if chunks:
                    self.vector_store_manager.create_or_load_vectorstore(chunks)
                else:
                    st.warning("Nincsenek feldolgozhat√≥ PDF-ek")
                    return self._create_empty_result()
            else:
                self.vector_store_manager.create_or_load_vectorstore()

            # üîÑ Betegadatok ford√≠t√°sa angolra
            st.info("üåê Betegadatok ford√≠t√°sa angolra a dokumentumkeres√©shez...")
            translated_data = translate_patient_data(patient_data, self.llm.openai_api_key)

            # üîé Relev√°ns inform√°ci√≥k keres√©se
            st.info("üîé Relev√°ns inform√°ci√≥k keres√©se...")
            symptoms = translated_data.get('symptoms', [])
            diagnosis = translated_data.get('diagnosis', '')

            relevant_docs = self.vector_store_manager.search_by_symptoms(
                symptoms=symptoms,
                diagnosis=diagnosis
            )

            if not relevant_docs:
                st.warning("Nem tal√°ltam relev√°ns inform√°ci√≥kat a Medline dokumentumokban")
                return self._create_empty_result()

            # Kontextus
            context = self.prepare_context(relevant_docs)

            # ü§ñ AI v√°lasz gener√°l√°sa magyar nyelven (magyar adatokkal)
            st.info("ü§ñ AI v√°lasz gener√°l√°sa...")

            input_data = {
                "context": context,
                "age": patient_data.get('age', 'ismeretlen'),
                "gender": patient_data.get('gender', 'ismeretlen'),
                "symptoms": ', '.join(patient_data.get('symptoms', [])) or 'nincs megadva',
                "duration": patient_data.get('duration', 'ismeretlen'),
                "severity": patient_data.get('severity', 'ismeretlen'),
                "diagnosis": patient_data.get('diagnosis', 'nincs megadva'),
                "existing_conditions": ', '.join(patient_data.get('existing_conditions', [])) or 'nincs',
                "medications": ', '.join(patient_data.get('medications', [])) or 'nincs'
            }

            response = self.chain.run(**input_data)

            result = self._parse_ai_response(response)
            result['timestamp'] = datetime.now().isoformat()
            result['sources'] = [doc.metadata.get('source', 'Unknown') for doc in relevant_docs]

            st.success("‚úÖ RAG elemz√©s sikeres!")
            return result

        except Exception as e:
            st.error(f"RAG elemz√©si hiba: {e}")
            return self._create_empty_result()

    
    def _parse_ai_response(self, response: str) -> Dict[str, Any]:
        """AI v√°lasz struktur√°lt form√°ba alak√≠t√°sa"""
        # Egyszer≈± parsing - k√©s≈ëbb lehet sophisticatedebb
        sections = {
            "patient_condition": "",
            "symptom_management": "",
            "recommended_specialist": "",
            "additional_info": ""
        }
        
        # Szekci√≥k keres√©se a v√°laszban
        current_section = None
        lines = response.split('\n')
        
        for line in lines:
            if "Milyen beteg" in line or "probl√©ma" in line:
                current_section = "patient_condition"
            elif "Mit tehet" in line or "t√ºnetek ellen" in line:
                current_section = "symptom_management"
            elif "orvoshoz" in line or "szakorvos" in line:
                current_section = "recommended_specialist"
            elif "Tov√°bbi" in line or "hasznos" in line:
                current_section = "additional_info"
            elif current_section and line.strip():
                sections[current_section] += line + "\n"
        
        # Tiszt√≠t√°s
        for key in sections:
            sections[key] = sections[key].strip()
        
        # Ha nem siker√ºlt parseolni, akkor az eg√©sz v√°laszt visszaadjuk
        if not any(sections.values()):
            sections["full_response"] = response
        
        return sections
    
    def _create_empty_result(self) -> Dict[str, Any]:
        """√úres eredm√©ny strukt√∫ra"""
        return {
            "patient_condition": "Nem √°ll rendelkez√©sre inform√°ci√≥",
            "symptom_management": "Nem √°ll rendelkez√©sre inform√°ci√≥",
            "recommended_specialist": "Nem √°ll rendelkez√©sre inform√°ci√≥",
            "additional_info": "Nem √°ll rendelkez√©sre inform√°ci√≥",
            "timestamp": datetime.now().isoformat(),
            "sources": []
        }
    
    def save_results(self, results: Dict[str, Any], patient_data: Dict[str, Any], 
                    export_path: Path = None) -> Dict[str, str]:
        """Eredm√©nyek ment√©se JSON √©s PDF form√°tumban"""
        if export_path is None:
            export_path = Path("rag_data/exports")
        
        export_path.mkdir(parents=True, exist_ok=True)
        
        # Teljes export adat √∂ssze√°ll√≠t√°sa
        export_data = {
            "rag_analysis": results,
            "patient_data": patient_data,
            "analysis_timestamp": results.get('timestamp', datetime.now().isoformat()),
            "case_id": patient_data.get('case_id', f"rag_{datetime.now().strftime('%Y%m%d%H%M%S')}")
        }
        
        # JSON ment√©s
        json_path = export_path / f"{export_data['case_id']}_rag.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        # PDF gener√°l√°s (a megl√©v≈ë PDF generator haszn√°lat√°val)
        try:
            from export.pdf_generator import generate_pdf
            
            # RAG eredm√©nyek hozz√°ad√°sa az export adatokhoz
            export_data_for_pdf = patient_data.copy()
            export_data_for_pdf['rag_analysis'] = results
            
            pdf_data = generate_pdf(export_data_for_pdf)
            if pdf_data:
                pdf_path = export_path / f"{export_data['case_id']}_rag.pdf"
                with open(pdf_path, 'wb') as f:
                    f.write(pdf_data.getvalue())
            else:
                pdf_path = None
                
        except Exception as e:
            st.error(f"PDF gener√°l√°si hiba: {e}")
            pdf_path = None
        
        return {
            "json_path": str(json_path),
            "pdf_path": str(pdf_path) if pdf_path else None
        }

# =============================================================================
# F≈ëf√ºggv√©ny a k√∂nny≈± haszn√°lathoz
# =============================================================================

def run_rag_analysis(patient_data: Dict[str, Any], openai_api_key: str = None) -> Dict[str, Any]:
    """
    RAG elemz√©s futtat√°sa
    
    Args:
        patient_data: Beteg adatok (a session state-b≈ël)
        openai_api_key: OpenAI API kulcs
        
    Returns:
        Dict: RAG elemz√©s eredm√©nye
    """
    # API kulcs lek√©r√©se
    if not openai_api_key:
        #openai_api_key = st.secrets.get("OPENAI_API_KEY")
        openai_api_key = os.getenv("OPENAI_API_KEY")
    
    if not openai_api_key:
        st.error("OpenAI API kulcs nem tal√°lhat√≥!")
        return {}
    
    # RAG Analyzer inicializ√°l√°sa
    analyzer = RAGAnalyzer(openai_api_key)
    
    # Elemz√©s futtat√°sa
    results = analyzer.analyze_patient_with_rag(patient_data)
    
    # Eredm√©nyek ment√©se
    save_paths = analyzer.save_results(results, patient_data)
    
    # Eredm√©nyek megjelen√≠t√©se
    st.markdown("### üß† RAG Elemz√©s Eredm√©nye")
    
    with st.expander("üìã Beteg √°llapota", expanded=True):
        st.markdown(results.get('patient_condition', 'Nincs inform√°ci√≥'))
    
    with st.expander("üíä Mit tehet a t√ºnetek ellen", expanded=True):
        st.markdown(results.get('symptom_management', 'Nincs inform√°ci√≥'))
    
    with st.expander("üë®‚Äç‚öïÔ∏è Aj√°nlott szakorvos", expanded=True):
        st.markdown(results.get('recommended_specialist', 'Nincs inform√°ci√≥'))
    
    with st.expander("‚ÑπÔ∏è Tov√°bbi inform√°ci√≥k", expanded=True):
        st.markdown(results.get('additional_info', 'Nincs inform√°ci√≥'))
    
    # Forr√°sok megjelen√≠t√©se
    if results.get('sources'):
        st.info(f"üìö Felhaszn√°lt forr√°sok: {', '.join(results['sources'])}")
    
    # Export linkek
    st.markdown("### üì• Let√∂lt√©s")
    col1, col2 = st.columns(2)
    
    with col1:
        if save_paths.get('json_path'):
            with open(save_paths['json_path'], 'r', encoding='utf-8') as f:
                st.download_button(
                    label="üìÑ RAG JSON let√∂lt√©se",
                    data=f.read(),
                    file_name=Path(save_paths['json_path']).name,
                    mime="application/json"
                )
    
    with col2:
        if save_paths.get('pdf_path'):
            with open(save_paths['pdf_path'], 'rb') as f:
                st.download_button(
                    label="üìë RAG PDF let√∂lt√©se",
                    data=f.read(),
                    file_name=Path(save_paths['pdf_path']).name,
                    mime="application/pdf"
                )
    
    return results