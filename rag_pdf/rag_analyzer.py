# =============================================================================
# rag_pdf/rag_analyzer.py - JAVÃTOTT VERZIÃ“
# =============================================================================
"""
RAG alapÃº PDF elemzÃ©s JAVÃTOTT VERZIÃ“ - deprecated fÃ¼ggvÃ©nyek kijavÃ­tva
"""
import os
import streamlit as st
from typing import List, Dict, Any, Optional
from datetime import datetime
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.prompts import PromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
#from langchain_chroma import Chroma
import json
from pathlib import Path

# Streamlitre kell
try:
    import pysqlite3
    import sys
    sys.modules["sqlite3"] = pysqlite3
except ImportError:
    print("âš ï¸ pysqlite3-binary nem elÃ©rhetÅ‘ â€“ SQLite override sikertelen")

# FordÃ­tÃ¡si segÃ©dfÃ¼ggvÃ©nyek
def translate_text(text: str, openai_api_key: str) -> str:
    if not text:
        return ""
    llm = ChatOpenAI(openai_api_key=openai_api_key, temperature=0)
    return llm.predict(f"Translate this Hungarian medical phrase to English: {text}").strip()

def translate_list(items: List[str], openai_api_key: str) -> List[str]:
    return [translate_text(item, openai_api_key) for item in items if item]

def translate_patient_data(patient_data: Dict[str, Any], openai_api_key: str) -> Dict[str, Any]:
    translated = patient_data.copy()
    translated['symptoms'] = translate_list(patient_data.get('symptoms', []), openai_api_key)
    translated['diagnosis'] = translate_text(patient_data.get('diagnosis', ''), openai_api_key)
    translated['existing_conditions'] = translate_list(patient_data.get('existing_conditions', []), openai_api_key)
    translated['medications'] = translate_list(patient_data.get('medications', []), openai_api_key)
    return translated

###

class RAGAnalyzer:
    """
    RAG alapÃº PDF elemzÃ©s JAVÃTOTT VERZIÃ“
    """
    
    def __init__(self, vector_store_path: str = "rag_pdf/vectorstore"):
        self.vector_store_path = vector_store_path
        self.embeddings = None
        self.vectorstore = None
        self.llm = None
        self.retrieval_chain = None
        self._initialize_components()
    
    def _initialize_components(self):
        """Komponensek inicializÃ¡lÃ¡sa JAVÃTOTT verziÃ³"""
        try:
            # âœ… JAVÃTVA: OpenAI API key kezelÃ©s
            api_key = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("OpenAI API key not found")
            
            # âœ… JAVÃTVA: Modern LangChain komponensek
            self.embeddings = OpenAIEmbeddings(
                openai_api_key=api_key,
                model="text-embedding-3-small"  # LegÃºjabb embedding model
            )
            
            self.llm = ChatOpenAI(
                openai_api_key=api_key,
                model="gpt-4",
                temperature=0.1,
                max_tokens=1500
            )
            
            # Vector store betÃ¶ltÃ©se vagy lÃ©trehozÃ¡sa
            self._load_or_create_vectorstore()
            
            # âœ… JAVÃTVA: Modern LCEL (LangChain Expression Language) chain
            self._create_retrieval_chain()
            
            print("âœ… RAG Analyzer sikeresen inicializÃ¡lva")
            
        except Exception as e:
            print(f"âŒ RAG Analyzer inicializÃ¡lÃ¡si hiba: {e}")
            raise
    
    def _load_or_create_vectorstore(self):
        """Vector store betÃ¶ltÃ©se vagy lÃ©trehozÃ¡sa"""
        try:
            if os.path.exists(self.vector_store_path):
                # âœ… JAVÃTVA: BetÃ¶ltÃ©s ellenÅ‘rzÃ©se
                self.vectorstore = Chroma(
                    persist_directory=self.vector_store_path,
                    embedding_function=self.embeddings
                )
                
                # EllenÅ‘rizzÃ¼k, hogy van-e tartalom
                collection_count = self.vectorstore._collection.count()
                if collection_count > 0:
                    print(f"âœ… Vector store betÃ¶ltve: {collection_count} dokumentum")
                else:
                    print("âš ï¸ Vector store Ã¼res, PDF-ek betÃ¶ltÃ©se szÃ¼ksÃ©ges")
                    self._load_pdfs_to_vectorstore()
            else:
                print("ğŸ“ Vector store nem lÃ©tezik, lÃ©trehozÃ¡s...")
                self._load_pdfs_to_vectorstore()
                
        except Exception as e:
            print(f"âŒ Vector store hiba: {e}")
            # Fallback: Ãºj vector store lÃ©trehozÃ¡sa
            self._load_pdfs_to_vectorstore()
    
    def _load_pdfs_to_vectorstore(self):
        """PDF-ek betÃ¶ltÃ©se a vector store-ba JAVÃTOTT verziÃ³"""
        try:
            # âœ… JAVÃTVA: PDF kÃ¶nyvtÃ¡r ellenÅ‘rzÃ©se
            pdf_directory = Path("medline_data/pdfs")
            if not pdf_directory.exists():
                print(f"âŒ PDF kÃ¶nyvtÃ¡r nem lÃ©tezik: {pdf_directory}")
                return
            
            pdf_files = list(pdf_directory.glob("*.pdf"))
            if not pdf_files:
                print("âŒ Nincsenek PDF fÃ¡jlok a kÃ¶nyvtÃ¡rban")
                return
            
            print(f"ğŸ“š PDF fÃ¡jlok betÃ¶ltÃ©se: {len(pdf_files)} fÃ¡jl")
            
            # âœ… JAVÃTVA: Dokumentumok feldolgozÃ¡sa
            all_documents = []
            
            for pdf_file in pdf_files:
                try:
                    # PDF betÃ¶ltÃ©se
                    loader = PyPDFLoader(str(pdf_file))
                    documents = loader.load()
                    
                    # Metadata hozzÃ¡adÃ¡sa
                    for doc in documents:
                        doc.metadata.update({
                            'source_file': pdf_file.name,
                            'file_type': 'medline_pdf',
                            'topic': self._extract_topic_from_filename(pdf_file.name)
                        })
                    
                    all_documents.extend(documents)
                    print(f"âœ… BetÃ¶ltve: {pdf_file.name} ({len(documents)} oldal)")
                    
                except Exception as e:
                    print(f"âŒ Hiba PDF betÃ¶ltÃ©sekor ({pdf_file.name}): {e}")
            
            if not all_documents:
                print("âŒ Nincsenek betÃ¶lthetÅ‘ dokumentumok")
                return
            
            # âœ… JAVÃTVA: Text splitting optimalizÃ¡lÃ¡sa
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,      # Kisebb chunk-ok a pontosabb retrievalÃ©rt
                chunk_overlap=200,    # ÃtfedÃ©s a kontextus megÅ‘rzÃ©sÃ©re
                length_function=len,
                separators=["\n\n", "\n", ". ", " ", ""]
            )
            
            split_documents = text_splitter.split_documents(all_documents)
            print(f"ğŸ“„ Dokumentumok feldarabolva: {len(split_documents)} chunk")
            
            # âœ… JAVÃTVA: Vector store lÃ©trehozÃ¡sa
            os.makedirs(self.vector_store_path, exist_ok=True)
            
            self.vectorstore = Chroma.from_documents(
                documents=split_documents,
                embedding=self.embeddings,
                persist_directory=self.vector_store_path
            )
            
            print(f"âœ… Vector store lÃ©trehozva: {len(split_documents)} dokumentum chunk")
            
        except Exception as e:
            print(f"âŒ PDF betÃ¶ltÃ©si hiba: {e}")
            raise
    
    def _extract_topic_from_filename(self, filename: str) -> str:
        """Topic kinyerÃ©se a fÃ¡jlnÃ©vbÅ‘l"""
        # medline_01_headache_20250730_095014.pdf
        parts = filename.replace('.pdf', '').split('_')
        if len(parts) >= 3:
            return parts[2]  # headache rÃ©sz
        return "unknown"
    
    def _create_retrieval_chain(self):
        """âœ… JAVÃTVA: Modern LCEL chain lÃ©trehozÃ¡sa"""
        if not self.vectorstore:
            raise ValueError("Vector store nincs inicializÃ¡lva")
        
        # âœ… JAVÃTVA: Magyar nyelvÅ± prompt template
        prompt_template = PromptTemplate.from_template("""
Te egy egÃ©szsÃ©gÃ¼gyi szakÃ©rtÅ‘ vagy, aki Medline Plus informÃ¡ciÃ³k alapjÃ¡n ad tanÃ¡csokat.

KONTEXTUS (Medline Plus dokumentumok):
{context}

BETEG ADATOK Ã‰S KÃ‰RDÃ‰S: {question}

FELADAT:
VÃ¡laszolj MAGYARUL a kÃ¶vetkezÅ‘ kÃ©rdÃ©sekre a Medline dokumentumok alapjÃ¡n:

1. **Mi lehet a beteg problÃ©mÃ¡ja?** - DiagnÃ³zis Ã©s magyarÃ¡zat
2. **Mit tehet a tÃ¼netek ellen?** - KezelÃ©si lehetÅ‘sÃ©gek Ã©s otthoni praktikÃ¡k  
3. **Milyen orvoshoz forduljon?** - SpecializÃ¡ciÃ³ Ã©s sÃ¼rgÅ‘ssÃ©g
4. **TovÃ¡bbi tanÃ¡csok** - MegelÅ‘zÃ©s Ã©s hasznos informÃ¡ciÃ³k

Ha nincs relevÃ¡ns informÃ¡ciÃ³, Ã­rd: "Nincs megfelelÅ‘ informÃ¡ciÃ³ a dokumentumokban"

VÃLASZ MAGYARUL:
""")

        # âœ… JAVÃTVA: Retriever konfigurÃ¡lÃ¡sa
        retriever = self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={
                "k": 5,  # Top 5 legrelvÃ¡nsabb chunk
                #"score_threshold": 0.3  # Minimum hasonlÃ³sÃ¡gi kÃ¼szÃ¶b
            }
        )
        
        # âœ… JAVÃTVA: Modern LCEL chain (LangChain Expression Language)
        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)
        
        self.retrieval_chain = (
            {
                "context": retriever | format_docs,
                "question": RunnablePassthrough()
            }
            | prompt_template
            | self.llm
            | StrOutputParser()
        )
        
        print("âœ… Modern LCEL retrieval chain lÃ©trehozva")
    
    def analyze_medical_case(self, case_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Orvosi eset elemzÃ©se JAVÃTOTT verziÃ³
        
        Args:
            case_data: Orvosi eset adatok (JSON)
            
        Returns:
            Dict: ElemzÃ©si eredmÃ©nyek
        """
        try:
            if not self.retrieval_chain:
                raise ValueError("RAG chain nincs inicializÃ¡lva")
            
            # âœ… JAVÃTVA: Query Ã¶sszeÃ¡llÃ­tÃ¡sa
            translated_data = translate_patient_data(case_data, os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY"))
            query = self._build_medical_query(translated_data)
            #query = self._build_medical_query(case_data)
            print(f"ğŸ” RAG Query: {query}")
            
            # âœ… JAVÃTVA: Modern invoke hasznÃ¡lata predict helyett
            with st.spinner("RAG elemzÃ©s folyamatban..."):
                rag_response = self.retrieval_chain.invoke(query)
            
            print(f"ğŸ“„ RAG Response: {rag_response[:200]}...")
            
            # âœ… JAVÃTVA: VÃ¡lasz feldolgozÃ¡sa
            analysis_result = self._parse_rag_response(rag_response, case_data)
            
            return analysis_result
            
        except Exception as e:
            print(f"âŒ RAG elemzÃ©si hiba: {e}")
            return {
                'success': False,
                'error': str(e),
                'rag_response': None,
                'medical_insights': []
            }
    
    def _build_medical_query(self, case_data: Dict[str, Any]) -> str:
        """âœ… JAVÃTVA: Orvosi query Ã¶sszeÃ¡llÃ­tÃ¡sa"""
        # Alapadatok kinyerÃ©se
        symptoms = case_data.get('symptoms', [])
        age = case_data.get('age', 'ismeretlen')
        gender = case_data.get('gender', 'ismeretlen')
        duration = case_data.get('duration', 'ismeretlen')
        diagnosis = case_data.get('diagnosis', '')
        existing_conditions = case_data.get('existing_conditions', [])
        medications = case_data.get('medications', [])
        
        # Query Ã¶sszeÃ¡llÃ­tÃ¡sa magyar nyelven
        query_parts = []
        
        query_parts.append(f"PÃ¡ciens: {age} Ã©ves {gender}")
        
        if symptoms:
            symptoms_text = ', '.join(symptoms)
            query_parts.append(f"TÃ¼netek: {symptoms_text}")
        
        if duration and duration != 'ismeretlen':
            query_parts.append(f"IdÅ‘tartam: {duration}")
        
        if diagnosis and diagnosis != "Nem sikerÃ¼lt diagnÃ³zist javasolni.":
            query_parts.append(f"LehetsÃ©ges diagnÃ³zis: {diagnosis}")
            
        if existing_conditions:
            query_parts.append(f"MeglÃ©vÅ‘ betegsÃ©gek: {', '.join(existing_conditions)}")
            
        if medications:
            query_parts.append(f"GyÃ³gyszerek: {', '.join(medications)}")
        
        main_query = " | ".join(query_parts)
        
        full_query = f"""
{main_query}

KÃ©rlek adj rÃ©szletes egÃ©szsÃ©gÃ¼gyi tanÃ¡csokat a Medline dokumentumok alapjÃ¡n!
"""
        
        return full_query.strip()
    
    def _parse_rag_response(self, rag_response: str, case_data: Dict[str, Any]) -> Dict[str, Any]:
        """âœ… JAVÃTVA: RAG vÃ¡lasz feldolgozÃ¡sa strukturÃ¡lt formÃ¡ba"""
        
        # âœ… JAVÃTVA: Ãœres vÃ¡lasz ellenÅ‘rzÃ©s
        if not rag_response or rag_response.strip() == "":
            return {
                'success': False,
                'error': 'Ãœres RAG vÃ¡lasz',
                'patient_condition': 'Nincs informÃ¡ciÃ³',
                'symptom_management': 'Nincs informÃ¡ciÃ³', 
                'recommended_specialist': 'Nincs informÃ¡ciÃ³',
                'additional_info': 'Nincs informÃ¡ciÃ³',
                'timestamp': datetime.now().isoformat(),
                'sources': []
            }
        
        # âœ… JAVÃTVA: "Nincs relevÃ¡ns informÃ¡ciÃ³" ellenÅ‘rzÃ©s
        if "nincs megfelelÅ‘ informÃ¡ciÃ³" in rag_response.lower() or "nincs relevÃ¡ns informÃ¡ciÃ³" in rag_response.lower():
            return {
                'success': False,
                'error': 'Nincs relevÃ¡ns informÃ¡ciÃ³ a dokumentumokban',
                'patient_condition': 'Nincs megfelelÅ‘ informÃ¡ciÃ³ a dokumentumokban',
                'symptom_management': 'Nincs megfelelÅ‘ informÃ¡ciÃ³ a dokumentumokban',
                'recommended_specialist': 'Nincs megfelelÅ‘ informÃ¡ciÃ³ a dokumentumokban', 
                'additional_info': 'Nincs megfelelÅ‘ informÃ¡ciÃ³ a dokumentumokban',
                'timestamp': datetime.now().isoformat(),
                'sources': []
            }
        
        # âœ… JAVÃTVA: StrukturÃ¡lt vÃ¡lasz kinyerÃ©se
        parsed_result = self._extract_structured_response(rag_response)
        
        # âœ… JAVÃTVA: EredmÃ©ny struktÃºra
        result = {
            'success': True,
            'patient_condition': parsed_result.get('patient_condition', 'Nem sikerÃ¼lt kinyerni'),
            'symptom_management': parsed_result.get('symptom_management', 'Nem sikerÃ¼lt kinyerni'),
            'recommended_specialist': parsed_result.get('recommended_specialist', 'Nem sikerÃ¼lt kinyerni'),
            'additional_info': parsed_result.get('additional_info', 'Nem sikerÃ¼lt kinyerni'),
            'timestamp': datetime.now().isoformat(),
            'sources': ['medline_pdf'],  # ÃltalÃ¡nos forrÃ¡s
            'full_response': rag_response  # Teljes vÃ¡lasz megÅ‘rzÃ©se
        }
        
        return result
    
    def _extract_structured_response(self, response: str) -> Dict[str, str]:
        #StrukturÃ¡lt vÃ¡lasz kinyerÃ©se a RAG response-bÃ³l sorszÃ¡m alapjÃ¡n

        sections = {
            "patient_condition": "",
            "symptom_management": "",
            "recommended_specialist": "",
            "additional_info": ""
        }

        import re

        # Regex a 4 szekciÃ³ cÃ­mÃ©nek megtalÃ¡lÃ¡sÃ¡ra
        pattern = r"(1\.\s\*\*.*?\*\*.*?)(?=2\.|\Z)|" \
                r"(2\.\s\*\*.*?\*\*.*?)(?=3\.|\Z)|" \
                r"(3\.\s\*\*.*?\*\*.*?)(?=4\.|\Z)|" \
                r"(4\.\s\*\*.*?\*\*.*)"

        matches = re.findall(pattern, response, flags=re.DOTALL)

        for i, match_group in enumerate(matches):
            for match in match_group:
                if match:
                    if i == 0:
                        sections["patient_condition"] = match.strip()
                    elif i == 1:
                        sections["symptom_management"] = match.strip()
                    elif i == 2:
                        sections["recommended_specialist"] = match.strip()
                    elif i == 3:
                        sections["additional_info"] = match.strip()

        # Fallback Ã¼zenet, ha valami kimarad
        for key in sections:
            if not sections[key]:
                sections[key] = "Nem sikerÃ¼lt relevÃ¡ns informÃ¡ciÃ³t talÃ¡lni"

        return sections

    
    def get_vectorstore_stats(self) -> Dict[str, Any]:
        """Vector store statisztikÃ¡k"""
        try:
            if not self.vectorstore:
                return {'error': 'Vector store nincs inicializÃ¡lva'}
            
            collection_count = self.vectorstore._collection.count()
            
            # Metadatok Ã¶sszegyÅ±jtÃ©se
            if collection_count > 0:
                # PÃ©lda dokumentumok lekÃ©rÃ©se
                sample_docs = self.vectorstore.similarity_search("medline", k=3)
                topics = set()
                sources = set()
                
                for doc in sample_docs:
                    if 'topic' in doc.metadata:
                        topics.add(doc.metadata['topic'])
                    if 'source_file' in doc.metadata:
                        sources.add(doc.metadata['source_file'])
                
                return {
                    'total_documents': collection_count,
                    'topics_found': list(topics),
                    'source_files': list(sources),
                    'sample_content': sample_docs[0].page_content[:200] if sample_docs else None
                }
            else:
                return {
                    'total_documents': 0,
                    'topics_found': [],
                    'source_files': [],
                    'sample_content': None
                }
                
        except Exception as e:
            return {'error': f'Stats lekÃ©rÃ©si hiba: {e}'}
    
    def test_retrieval(self, query: str, k: int = 3) -> Dict[str, Any]:
        """âœ… JAVÃTVA: Retrieval tesztelÃ©se"""
        try:
            if not self.vectorstore:
                return {'error': 'Vector store nincs inicializÃ¡lva'}
            
            # Similarity search
            docs = self.vectorstore.similarity_search(query, k=k)
            
            results = []
            for i, doc in enumerate(docs):
                results.append({
                    'rank': i + 1,
                    'content': doc.page_content[:300],
                    'metadata': doc.metadata,
                    'content_length': len(doc.page_content)
                })
            
            return {
                'query': query,
                'results_count': len(results),
                'results': results
            }
            
        except Exception as e:
            return {'error': f'Retrieval teszt hiba: {e}'}

# =============================================================================
# HIÃNYZÃ“ FÃœGGVÃ‰NY HOZZÃADÃSA - kompatibilitÃ¡shoz
# =============================================================================

def run_rag_analysis(patient_data: Dict[str, Any], openai_api_key: str = None) -> Dict[str, Any]:
    """
    âœ… JAVÃTVA: RAG elemzÃ©s futtatÃ¡sa - kompatibilitÃ¡s fÃ¼ggvÃ©ny
    
    Args:
        patient_data: Beteg adatok (a session state-bÅ‘l)
        openai_api_key: OpenAI API kulcs (opcionÃ¡lis)
        
    Returns:
        Dict: RAG elemzÃ©s eredmÃ©nye
    """
    try:
        st.info("ğŸ” RAG alapÃº elemzÃ©s indÃ­tÃ¡sa...")
        
        # API kulcs ellenÅ‘rzÃ©se
        if not openai_api_key:
            openai_api_key = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY")
        
        if not openai_api_key:
            st.error("âŒ OpenAI API kulcs nem talÃ¡lhatÃ³!")
            return _create_empty_result()
        
        # RAG Analyzer inicializÃ¡lÃ¡sa
        analyzer = RAGAnalyzer()
        
        # ElemzÃ©s futtatÃ¡sa
        st.info("ğŸ¤– AI elemzÃ©s futtatÃ¡sa...")
        results = analyzer.analyze_medical_case(patient_data)
        
        # EredmÃ©nyek ellenÅ‘rzÃ©se
        if not results.get('success', False):
            st.warning(f"âš ï¸ RAG elemzÃ©s problÃ©mÃ¡ba Ã¼tkÃ¶zÃ¶tt: {results.get('error', 'Ismeretlen hiba')}")
            return _create_empty_result()
        
        # EredmÃ©nyek mentÃ©se
        save_paths = _save_rag_results(results, patient_data)
        
        # UI megjelenÃ­tÃ©s
        _display_rag_results(results, save_paths)
        
        st.success("âœ… RAG elemzÃ©s sikeresen befejezve!")
        return results
        
    except Exception as e:
        st.error(f"âŒ RAG elemzÃ©si hiba: {e}")
        print(f"RAG hiba rÃ©szletei: {e}")
        return _create_empty_result()

def _create_empty_result() -> Dict[str, Any]:
    """Ãœres eredmÃ©ny struktÃºra"""
    return {
        'success': False,
        'patient_condition': "Nem Ã¡ll rendelkezÃ©sre informÃ¡ciÃ³",
        'symptom_management': "Nem Ã¡ll rendelkezÃ©sre informÃ¡ciÃ³", 
        'recommended_specialist': "Nem Ã¡ll rendelkezÃ©sre informÃ¡ciÃ³",
        'additional_info': "Nem Ã¡ll rendelkezÃ©sre informÃ¡ciÃ³",
        'timestamp': datetime.now().isoformat(),
        'sources': []
    }

def _save_rag_results(results: Dict[str, Any], patient_data: Dict[str, Any]) -> Dict[str, str]:
    """RAG eredmÃ©nyek mentÃ©se"""
    try:
        export_path = Path("rag_data/exports")
        export_path.mkdir(parents=True, exist_ok=True)
        
        # Export adat Ã¶sszeÃ¡llÃ­tÃ¡sa
        case_id = patient_data.get('case_id', f"rag_{datetime.now().strftime('%Y%m%d%H%M%S')}")
        export_data = {
            "rag_analysis": results,
            "patient_data": patient_data,
            "analysis_timestamp": results.get('timestamp', datetime.now().isoformat()),
            "case_id": case_id
        }
        
        # JSON mentÃ©s
        json_path = export_path / f"{case_id}_rag.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        return {
            "json_path": str(json_path),
            "pdf_path": None  # PDF generÃ¡lÃ¡s opcionÃ¡lis
        }
        
    except Exception as e:
        print(f"RAG eredmÃ©ny mentÃ©si hiba: {e}")
        return {"json_path": None, "pdf_path": None}

def _display_rag_results(results: Dict[str, Any], save_paths: Dict[str, str]):
    """RAG eredmÃ©nyek megjelenÃ­tÃ©se"""
    st.markdown("### ğŸ§  RAG ElemzÃ©s EredmÃ©nye")
    
    # EredmÃ©nyek megjelenÃ­tÃ©se expander-ekben
    with st.expander("ğŸ“‹ Beteg Ã¡llapota", expanded=True):
        st.markdown(results.get('patient_condition', 'Nincs informÃ¡ciÃ³'))
    
    with st.expander("ğŸ’Š Mit tehet a tÃ¼netek ellen", expanded=True):
        st.markdown(results.get('symptom_management', 'Nincs informÃ¡ciÃ³'))
    
    with st.expander("ğŸ‘¨â€âš•ï¸ AjÃ¡nlott szakorvos", expanded=True):
        st.markdown(results.get('recommended_specialist', 'Nincs informÃ¡ciÃ³'))
    
    with st.expander("â„¹ï¸ TovÃ¡bbi informÃ¡ciÃ³k", expanded=True):
        st.markdown(results.get('additional_info', 'Nincs informÃ¡ciÃ³'))
    
    # ForrÃ¡sok megjelenÃ­tÃ©se
    if results.get('sources'):
        st.info(f"ğŸ“š FelhasznÃ¡lt forrÃ¡sok: {', '.join(results['sources'])}")
    
    # LetÃ¶ltÃ©si lehetÅ‘sÃ©gek
    if save_paths.get('json_path'):
        st.markdown("### ğŸ“¥ LetÃ¶ltÃ©s")
        try:
            with open(save_paths['json_path'], 'r', encoding='utf-8') as f:
                st.download_button(
                    label="ğŸ“„ RAG JSON letÃ¶ltÃ©se",
                    data=f.read(),
                    file_name=Path(save_paths['json_path']).name,
                    mime="application/json"
                )
        except Exception as e:
            st.error(f"LetÃ¶ltÃ©si hiba: {e}")